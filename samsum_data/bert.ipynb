{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed386fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb9040d9f394173b9a4f1361a535030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmcsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vmcsa\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vmcsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341724593f204fa6adce114309449cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc62f0b11ed9433a9df419a64462c560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a7e4d6ed7d47a5a5373a5c0db519cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425f48f6b61d4b7590a88a83bcfae5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8293902a6c6c4eb88ec67e89af79ee3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\vmcsa\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\bart\\modeling_bart.py:496: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Original Dialogue: Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "Model Summary   : Hannah asks Amanda for Betty's number. Amanda can't find it. Hannah asks Larry. Amanda asks Larry to call Betty.\n",
      "Reference Summary: Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
      "\n",
      "Sample 2:\n",
      "Original Dialogue: Eric: MACHINE!\n",
      "Rob: That's so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it's really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I'll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I'll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "Model Summary   : Eric: Is this his only stand-up? I'll check. There are some of his stand-ups on youtube.\n",
      "Reference Summary: Eric and Rob are going to watch a stand-up on youtube.\n",
      "\n",
      "Sample 3:\n",
      "Original Dialogue: Lenny: Babe, can you help me with something?\n",
      "Bob: Sure, what's up?\n",
      "Lenny: Which one should I pick?\n",
      "Bob: Send me photos\n",
      "Lenny:  <file_photo>\n",
      "Lenny:  <file_photo>\n",
      "Lenny:  <file_photo>\n",
      "Bob: I like the first ones best\n",
      "Lenny: But I already have purple trousers. Does it make sense to have two pairs?\n",
      "Bob: I have four black pairs :D :D\n",
      "Lenny: yeah, but shouldn't I pick a different color?\n",
      "Bob: what matters is what you'll give you the most outfit options\n",
      "Lenny: So I guess I'll buy the first or the third pair then\n",
      "Bob: Pick the best quality then\n",
      "Lenny: ur right, thx\n",
      "Bob: no prob :)\n",
      "Model Summary   : Lenny: Babe, can you help me with something? Bob: Sure, what's up? Lenny: Which one should I pick?Bob: Send me photos. Lenny says he'll buy the first or the third pair.\n",
      "Reference Summary: Lenny can't decide which trousers to buy. Bob advised Lenny on that topic. Lenny goes with Bob's advice to pick the trousers that are of best quality.\n",
      "\n",
      "Sample 4:\n",
      "Original Dialogue: Will: hey babe, what do you want for dinner tonight?\n",
      "Emma:  gah, don't even worry about it tonight\n",
      "Will: what do you mean? everything ok?\n",
      "Emma: not really, but it's ok, don't worry about cooking though, I'm not hungry\n",
      "Will: Well what time will you be home?\n",
      "Emma: soon, hopefully\n",
      "Will: you sure? Maybe you want me to pick you up?\n",
      "Emma: no no it's alright. I'll be home soon, i'll tell you when I get home. \n",
      "Will: Alright, love you. \n",
      "Emma: love you too. \n",
      "Model Summary   : Emma:  gah, don't even worry about it tonight. Will:  Maybe you want me to pick you up? Emma: no no it's alright. I'll be home soon.\n",
      "Reference Summary: Emma will be home soon and she will let Will know.\n",
      "\n",
      "Sample 5:\n",
      "Original Dialogue: Ollie: Hi , are you in Warsaw\n",
      "Jane: yes, just back! Btw are you free for diner the 19th?\n",
      "Ollie: nope!\n",
      "Jane: and the  18th?\n",
      "Ollie: nope, we have this party and you must be there, remember?\n",
      "Jane: oh right! i lost my calendar..  thanks for reminding me\n",
      "Ollie: we have lunch this week?\n",
      "Jane: with pleasure!\n",
      "Ollie: friday?\n",
      "Jane: ok\n",
      "Jane: what do you mean \" we don't have any more whisky!\" lol..\n",
      "Ollie: what!!!\n",
      "Jane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\n",
      "Ollie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\n",
      "Jane: dont' worry, we'll check on friday.\n",
      "Ollie: don't forget to bring some sun with you\n",
      "Jane: I can't wait to be in Morocco..\n",
      "Ollie: enjoy and see you friday\n",
      "Jane: sorry Ollie, i'm very busy, i won't have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\n",
      "Ollie: ok for tea!\n",
      "Jane: I'm on my way..\n",
      "Ollie: tea is ready, did you bring the pastries?\n",
      "Jane: I already ate them all... see you in a minute\n",
      "Ollie: ok\n",
      "Model Summary   : Ollie calls his friend in Warsaw, Poland. He is in the middle of a week-long trip to Morocco. Ollie asks if he can join him for lunch.\n",
      "Reference Summary: Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
      "\n",
      "Sample 6:\n",
      "Original Dialogue: Benjamin: Hey guys, what are we doing with the keys today?\n",
      "Hilary: I've got them. Whoever wants them can meet me at lunchtime or after\n",
      "Elliot: I'm ok. We're meeting for the drinks in the evening anyway and I guess we'll be going back to the apartment together?\n",
      "Hilary: Yeah, I guess so\n",
      "Daniel: I'm with Hilary atm and won't let go of her for the rest of the day, so any option you guys choose is good for me\n",
      "Benjamin: Hmm I might actually pass by at lunchtime, take the keys and go take a nap. I'm sooo tired after yesterday\n",
      "Hilary: Sounds good. We'll be having lunch with some French people (the ones who work on the history of food in colonial Mexico - I already see you yawning your head off)\n",
      "Benjamin: YAAAAWN ðŸ™Š Where and where are you meeting?\n",
      "Hilary: So I'm meeting them at the entrance to the conference hall at 2 pm and then we'll head to this place called La Cantina. Italian cuisine, which is quite funny, but that's what they've chosen\n",
      "Benjamin: Interesting ðŸ˜± To be honest, Hilary, I almost feel like changing my mind. Wanting to take this nap might end up costing me to dear\n",
      "Hilary: Oh come on ðŸ˜‚\n",
      "Benjamin: All these terrible obstacles on mu way to bed might just prove to much to take\n",
      "Hilary: We'll try to avoid talking about their subject of research. Oh wait, no, I'm actually meeting them because I wanted to chat about their research lol\n",
      "Elliot: ðŸ™‰\n",
      "Hilary: Do join us, we're going to have fun. And then you'll take the keys and take this most deserved of naps\n",
      "Elliot: Sounds like a plan ðŸ˜‚\n",
      "Hilary: ðŸ˜Ž\n",
      "Elliot: See you at 2 then xx\n",
      "Model Summary   : Hilary: I've got the keys. Whoever wants them can meet me at lunchtime or after. We'll be having lunch with some French people (the ones who work on the history of food in colonial Mexico - I already see you yawning your head off)\n",
      "Reference Summary: Hilary has the keys to the apartment. Benjamin wants to get them and go take a nap. Hilary is having lunch with some French people at La Cantina. Hilary is meeting them at the entrance to the conference hall at 2 pm. Benjamin and Elliot might join them. They're meeting for the drinks in the evening.\n",
      "\n",
      "Sample 7:\n",
      "Original Dialogue: Max: Know any good sites to buy clothes from?\n",
      "Payton: Sure :) <file_other> <file_other> <file_other> <file_other> <file_other> <file_other> <file_other>\n",
      "Max: That's a lot of them!\n",
      "Payton: Yeah, but they have different things so I usually buy things from 2 or 3 of them.\n",
      "Max: I'll check them out. Thanks. \n",
      "Payton: No problem :)\n",
      "Max: How about u?\n",
      "Payton: What about me?\n",
      "Max: Do u like shopping?\n",
      "Payton: Yes and no.\n",
      "Max: How come?\n",
      "Payton: I like browsing, trying on, looking in the mirror and seeing how I look, but not always buying.\n",
      "Max: Y not?\n",
      "Payton: Isn't it obvious? ;)\n",
      "Max: Sry ;)\n",
      "Payton: If I bought everything I liked, I'd have nothing left to live on ;)\n",
      "Max: Same here, but probably different category ;)\n",
      "Payton: Lol\n",
      "Max: So what do u usually buy?\n",
      "Payton: Well, I have 2 things I must struggle to resist!\n",
      "Max: Which are?\n",
      "Payton: Clothes, ofc ;)\n",
      "Max: Right. And the second one?\n",
      "Payton: Books. I absolutely love reading!\n",
      "Max: Gr8! What books do u read?\n",
      "Payton: Everything I can get my hands on :)\n",
      "Max: Srsly?\n",
      "Payton: Yup :)\n",
      "Model Summary   : \"I like browsing, trying on, looking in the mirror and seeing how I look, but not always buying\" \"If I bought everything I liked, I'd have nothing left to live on\" \"I absolutely love reading! I must struggle to resist!\"\n",
      "Reference Summary: Payton provides Max with websites selling clothes. Payton likes browsing and trying on the clothes but not necessarily buying them. Payton usually buys clothes and books as he loves reading.\n",
      "\n",
      "Sample 8:\n",
      "Original Dialogue: Rita: I'm so bloody tired. Falling asleep at work. :-(\n",
      "Tina: I know what you mean.\n",
      "Tina: I keep on nodding off at my keyboard hoping that the boss doesn't notice..\n",
      "Rita: The time just keeps on dragging on and on and on.... \n",
      "Rita: I keep on looking at the clock and there's still 4 hours of this drudgery to go.\n",
      "Tina: Times like these I really hate my work.\n",
      "Rita: I'm really not cut out for this level of boredom.\n",
      "Tina: Neither am I.\n",
      "Model Summary   : Rita: I'm really not cut out for this level of boredom. Tina: Neither am I.\n",
      "Reference Summary: Rita and Tina are bored at work and have still 4 hours left.\n",
      "\n",
      "Sample 9:\n",
      "Original Dialogue: Beatrice: I am in town, shopping. They have nice scarfs in the shop next to the church. Do you want one?\n",
      "Leo: No, thanks\n",
      "Beatrice: But you don't have a scarf.\n",
      "Leo: Because I don't need it.\n",
      "Beatrice: Last winter you had a cold all the time. A scarf could help.\n",
      "Leo: I don't like them.\n",
      "Beatrice: Actually, I don't care. You will get a scarf.\n",
      "Leo: How understanding of you!\n",
      "Beatrice: You were complaining the whole winter that you're going to die. I've had enough.\n",
      "Leo: Eh.\n",
      "Model Summary   : Leo was shopping when his wife, Beatrice, asked him for a scarf. He said he didn't need one because he had a cold all the time. Beatrice said she would get him a scarf if he wanted one.\n",
      "Reference Summary: Beatrice wants to buy Leo a scarf, but he doesn't like scarves. She cares about his health and will buy him a scarf no matter his opinion.\n",
      "\n",
      "Sample 10:\n",
      "Original Dialogue: Ivan: hey eric\n",
      "Eric: yeah man\n",
      "Ivan: so youre coming to the wedding\n",
      "Eric: your brother's\n",
      "Ivan: yea\n",
      "Eric: i dont know mannn\n",
      "Ivan: YOU DONT KNOW??\n",
      "Eric: i just have a lot to do at home, plus i dont know if my parents would let me\n",
      "Ivan: ill take care of your parents\n",
      "Eric: youre telling me you have the guts to talk to them XD\n",
      "Ivan: thats my problem\n",
      "Eric: okay man, if you say so\n",
      "Ivan: yea just be there \n",
      "Eric: alright\n",
      "Model Summary   : Ivan and Eric are at the wedding of Ivan's brother. Ivan asks Eric if he is going to the wedding. Eric says he doesn't know if his parents would let him. Ivan says he will take care of his parents.\n",
      "Reference Summary: Eric doesn't know if his parents let him go to Ivan's brother's wedding. Ivan will talk to them.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load test data from test.json\n",
    "with open(\"test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Use only the first 10 dialogues\n",
    "samples = data[:10]\n",
    "\n",
    "# Load summarization pipeline using Facebook's BART model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Summarize and print results\n",
    "for i, sample in enumerate(samples):\n",
    "    dialogue = sample[\"dialogue\"]\n",
    "    summary = summarizer(dialogue, max_length=60, min_length=10, do_sample=False)[0][\"summary_text\"]\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(\"Original Dialogue:\", dialogue)\n",
    "    print(\"Model Summary   :\", summary)\n",
    "    print(\"Reference Summary:\", sample[\"summary\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a23ead",
   "metadata": {},
   "source": [
    "# Using the SAMSum Dataset with Pegasus Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7673c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Original Dialogue: Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "Model Summary    : Amanda can't find Betty's number. Larry called her last time they were at the park together.\n",
      "Reference Summary: Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
      "\n",
      "Sample 2:\n",
      "Original Dialogue: Eric: MACHINE!\n",
      "Rob: That's so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it's really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I'll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I'll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "Model Summary    : Eric, Rob and Rob will watch the Russian comedian's stand-up on YouTube.\n",
      "Reference Summary: Eric and Rob are going to watch a stand-up on youtube.\n",
      "\n",
      "Sample 3:\n",
      "Original Dialogue: Lenny: Babe, can you help me with something?\n",
      "Bob: Sure, what's up?\n",
      "Lenny: Which one should I pick?\n",
      "Bob: Send me photos\n",
      "Lenny:  <file_photo>\n",
      "Lenny:  <file_photo>\n",
      "Lenny:  <file_photo>\n",
      "Bob: I like the first ones best\n",
      "Lenny: But I already have purple trousers. Does it make sense to have two pairs?\n",
      "Bob: I have four black pairs :D :D\n",
      "Lenny: yeah, but shouldn't I pick a different color?\n",
      "Bob: what matters is what you'll give you the most outfit options\n",
      "Lenny: So I guess I'll buy the first or the third pair then\n",
      "Bob: Pick the best quality then\n",
      "Lenny: ur right, thx\n",
      "Bob: no prob :)\n",
      "Model Summary    : Lenny wants to buy purple trousers. Bob likes the first ones best. Lenny already has purple trousers.\n",
      "Reference Summary: Lenny can't decide which trousers to buy. Bob advised Lenny on that topic. Lenny goes with Bob's advice to pick the trousers that are of best quality.\n",
      "\n",
      "Sample 4:\n",
      "Original Dialogue: Will: hey babe, what do you want for dinner tonight?\n",
      "Emma:  gah, don't even worry about it tonight\n",
      "Will: what do you mean? everything ok?\n",
      "Emma: not really, but it's ok, don't worry about cooking though, I'm not hungry\n",
      "Will: Well what time will you be home?\n",
      "Emma: soon, hopefully\n",
      "Will: you sure? Maybe you want me to pick you up?\n",
      "Emma: no no it's alright. I'll be home soon, i'll tell you when I get home. \n",
      "Will: Alright, love you. \n",
      "Emma: love you too. \n",
      "Model Summary    : Emma will be home soon. She will tell Will when she gets home.\n",
      "Reference Summary: Emma will be home soon and she will let Will know.\n",
      "\n",
      "Sample 5:\n",
      "Original Dialogue: Ollie: Hi , are you in Warsaw\n",
      "Jane: yes, just back! Btw are you free for diner the 19th?\n",
      "Ollie: nope!\n",
      "Jane: and the  18th?\n",
      "Ollie: nope, we have this party and you must be there, remember?\n",
      "Jane: oh right! i lost my calendar..  thanks for reminding me\n",
      "Ollie: we have lunch this week?\n",
      "Jane: with pleasure!\n",
      "Ollie: friday?\n",
      "Jane: ok\n",
      "Jane: what do you mean \" we don't have any more whisky!\" lol..\n",
      "Ollie: what!!!\n",
      "Jane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\n",
      "Ollie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\n",
      "Jane: dont' worry, we'll check on friday.\n",
      "Ollie: don't forget to bring some sun with you\n",
      "Jane: I can't wait to be in Morocco..\n",
      "Ollie: enjoy and see you friday\n",
      "Jane: sorry Ollie, i'm very busy, i won't have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\n",
      "Ollie: ok for tea!\n",
      "Jane: I'm on my way..\n",
      "Ollie: tea is ready, did you bring the pastries?\n",
      "Jane: I already ate them all... see you in a minute\n",
      "Ollie: ok\n",
      "Model Summary    : Jane is back in Warsaw. She lost her calendar. She's on her way to Morocco. They'll check on Friday.\n",
      "Reference Summary: Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
      "\n",
      "Sample 6:\n",
      "Original Dialogue: Benjamin: Hey guys, what are we doing with the keys today?\n",
      "Hilary: I've got them. Whoever wants them can meet me at lunchtime or after\n",
      "Elliot: I'm ok. We're meeting for the drinks in the evening anyway and I guess we'll be going back to the apartment together?\n",
      "Hilary: Yeah, I guess so\n",
      "Daniel: I'm with Hilary atm and won't let go of her for the rest of the day, so any option you guys choose is good for me\n",
      "Benjamin: Hmm I might actually pass by at lunchtime, take the keys and go take a nap. I'm sooo tired after yesterday\n",
      "Hilary: Sounds good. We'll be having lunch with some French people (the ones who work on the history of food in colonial Mexico - I already see you yawning your head off)\n",
      "Benjamin: YAAAAWN ðŸ™Š Where and where are you meeting?\n",
      "Hilary: So I'm meeting them at the entrance to the conference hall at 2 pm and then we'll head to this place called La Cantina. Italian cuisine, which is quite funny, but that's what they've chosen\n",
      "Benjamin: Interesting ðŸ˜± To be honest, Hilary, I almost feel like changing my mind. Wanting to take this nap might end up costing me to dear\n",
      "Hilary: Oh come on ðŸ˜‚\n",
      "Benjamin: All these terrible obstacles on mu way to bed might just prove to much to take\n",
      "Hilary: We'll try to avoid talking about their subject of research. Oh wait, no, I'm actually meeting them because I wanted to chat about their research lol\n",
      "Elliot: ðŸ™‰\n",
      "Hilary: Do join us, we're going to have fun. And then you'll take the keys and take this most deserved of naps\n",
      "Elliot: Sounds like a plan ðŸ˜‚\n",
      "Hilary: ðŸ˜Ž\n",
      "Elliot: See you at 2 then xx\n",
      "Model Summary    : Hilary has the keys for the keys today. Elliot and Daniel are meeting for drinks in the evening. Benjamin might pass by at lunchtime and take the keys and take a nap. Hilary is meeting French people at La Cantina at 2 pm.\n",
      "Reference Summary: Hilary has the keys to the apartment. Benjamin wants to get them and go take a nap. Hilary is having lunch with some French people at La Cantina. Hilary is meeting them at the entrance to the conference hall at 2 pm. Benjamin and Elliot might join them. They're meeting for the drinks in the evening.\n",
      "\n",
      "Sample 7:\n",
      "Original Dialogue: Max: Know any good sites to buy clothes from?\n",
      "Payton: Sure :) <file_other> <file_other> <file_other> <file_other> <file_other> <file_other> <file_other>\n",
      "Max: That's a lot of them!\n",
      "Payton: Yeah, but they have different things so I usually buy things from 2 or 3 of them.\n",
      "Max: I'll check them out. Thanks. \n",
      "Payton: No problem :)\n",
      "Max: How about u?\n",
      "Payton: What about me?\n",
      "Max: Do u like shopping?\n",
      "Payton: Yes and no.\n",
      "Max: How come?\n",
      "Payton: I like browsing, trying on, looking in the mirror and seeing how I look, but not always buying.\n",
      "Max: Y not?\n",
      "Payton: Isn't it obvious? ;)\n",
      "Max: Sry ;)\n",
      "Payton: If I bought everything I liked, I'd have nothing left to live on ;)\n",
      "Max: Same here, but probably different category ;)\n",
      "Payton: Lol\n",
      "Max: So what do u usually buy?\n",
      "Payton: Well, I have 2 things I must struggle to resist!\n",
      "Max: Which are?\n",
      "Payton: Clothes, ofc ;)\n",
      "Max: Right. And the second one?\n",
      "Payton: Books. I absolutely love reading!\n",
      "Max: Gr8! What books do u read?\n",
      "Payton: Everything I can get my hands on :)\n",
      "Max: Srsly?\n",
      "Payton: Yup :)\n",
      "Model Summary    : Max will check out some good sites to buy clothes from. Payton will buy clothes from 2 or 3 of them.\n",
      "Reference Summary: Payton provides Max with websites selling clothes. Payton likes browsing and trying on the clothes but not necessarily buying them. Payton usually buys clothes and books as he loves reading.\n",
      "\n",
      "Sample 8:\n",
      "Original Dialogue: Rita: I'm so bloody tired. Falling asleep at work. :-(\n",
      "Tina: I know what you mean.\n",
      "Tina: I keep on nodding off at my keyboard hoping that the boss doesn't notice..\n",
      "Rita: The time just keeps on dragging on and on and on.... \n",
      "Rita: I keep on looking at the clock and there's still 4 hours of this drudgery to go.\n",
      "Tina: Times like these I really hate my work.\n",
      "Rita: I'm really not cut out for this level of boredom.\n",
      "Tina: Neither am I.\n",
      "Model Summary    : Rita is tired and falling asleep at work. Tina is bored.\n",
      "Reference Summary: Rita and Tina are bored at work and have still 4 hours left.\n",
      "\n",
      "Sample 9:\n",
      "Original Dialogue: Beatrice: I am in town, shopping. They have nice scarfs in the shop next to the church. Do you want one?\n",
      "Leo: No, thanks\n",
      "Beatrice: But you don't have a scarf.\n",
      "Leo: Because I don't need it.\n",
      "Beatrice: Last winter you had a cold all the time. A scarf could help.\n",
      "Leo: I don't like them.\n",
      "Beatrice: Actually, I don't care. You will get a scarf.\n",
      "Leo: How understanding of you!\n",
      "Beatrice: You were complaining the whole winter that you're going to die. I've had enough.\n",
      "Leo: Eh.\n",
      "Model Summary    : Leo doesn't want a scarf because he had a cold all the time last winter.\n",
      "Reference Summary: Beatrice wants to buy Leo a scarf, but he doesn't like scarves. She cares about his health and will buy him a scarf no matter his opinion.\n",
      "\n",
      "Sample 10:\n",
      "Original Dialogue: Ivan: hey eric\n",
      "Eric: yeah man\n",
      "Ivan: so youre coming to the wedding\n",
      "Eric: your brother's\n",
      "Ivan: yea\n",
      "Eric: i dont know mannn\n",
      "Ivan: YOU DONT KNOW??\n",
      "Eric: i just have a lot to do at home, plus i dont know if my parents would let me\n",
      "Ivan: ill take care of your parents\n",
      "Eric: youre telling me you have the guts to talk to them XD\n",
      "Ivan: thats my problem\n",
      "Eric: okay man, if you say so\n",
      "Ivan: yea just be there \n",
      "Eric: alright\n",
      "Model Summary    : Eric is coming to Ivan's brother's wedding. Eric doesn't know if his parents will let him come.\n",
      "Reference Summary: Eric doesn't know if his parents let him go to Ivan's brother's wedding. Ivan will talk to them.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"transformersbook/pegasus-samsum\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"transformersbook/pegasus-samsum\")\n",
    "\n",
    "# Load test data from test.json\n",
    "with open(\"test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Use only the first 10 dialogues\n",
    "samples = data[:10]\n",
    "\n",
    "# Generate and print summaries\n",
    "for i, sample in enumerate(samples):\n",
    "    dialogue = sample[\"dialogue\"]\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(dialogue, truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_length=60,\n",
    "        min_length=10,\n",
    "        num_beams=4,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(\"Original Dialogue:\", dialogue)\n",
    "    print(\"Model Summary    :\", summary)\n",
    "    print(\"Reference Summary:\", sample[\"summary\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cdb171",
   "metadata": {},
   "source": [
    "# Using Pipeline for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2ca81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1:\n",
      "Original Dialogue: Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him ðŸ™‚\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "Model Summary    : Amanda can't find Betty's number. Larry called her last time they were at the park together.\n",
      "Reference Summary: Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
      "\n",
      "Sample 2:\n",
      "Original Dialogue: Eric: MACHINE!\n",
      "Rob: That's so gr8!\n",
      "Eric: I know! And shows how Americans see Russian ;)\n",
      "Rob: And it's really funny!\n",
      "Eric: I know! I especially like the train part!\n",
      "Rob: Hahaha! No one talks to the machine like that!\n",
      "Eric: Is this his only stand-up?\n",
      "Rob: Idk. I'll check.\n",
      "Eric: Sure.\n",
      "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
      "Eric: Gr8! I'll watch them now!\n",
      "Rob: Me too!\n",
      "Eric: MACHINE!\n",
      "Rob: MACHINE!\n",
      "Eric: TTYL?\n",
      "Rob: Sure :)\n",
      "Model Summary    : Eric, Rob and Rob will watch the Russian comedian's stand-up.\n",
      "Reference Summary: Eric and Rob are going to watch a stand-up on youtube.\n",
      "\n",
      "Sample 3:\n",
      "Original Dialogue: Lenny: Babe, can you help me with something?\n",
      "Bob: Sure, what's up?\n",
      "Lenny: Which one should I pick?\n",
      "Bob: Send me photos\n",
      "Lenny:  <file_photo>\n",
      "Lenny:  <file_photo>\n",
      "Lenny:  <file_photo>\n",
      "Bob: I like the first ones best\n",
      "Lenny: But I already have purple trousers. Does it make sense to have two pairs?\n",
      "Bob: I have four black pairs :D :D\n",
      "Lenny: yeah, but shouldn't I pick a different color?\n",
      "Bob: what matters is what you'll give you the most outfit options\n",
      "Lenny: So I guess I'll buy the first or the third pair then\n",
      "Bob: Pick the best quality then\n",
      "Lenny: ur right, thx\n",
      "Bob: no prob :)\n",
      "Model Summary    : Lenny will buy the first or the third pair of purple trousers from Bob.\n",
      "Reference Summary: Lenny can't decide which trousers to buy. Bob advised Lenny on that topic. Lenny goes with Bob's advice to pick the trousers that are of best quality.\n",
      "\n",
      "Sample 4:\n",
      "Original Dialogue: Will: hey babe, what do you want for dinner tonight?\n",
      "Emma:  gah, don't even worry about it tonight\n",
      "Will: what do you mean? everything ok?\n",
      "Emma: not really, but it's ok, don't worry about cooking though, I'm not hungry\n",
      "Will: Well what time will you be home?\n",
      "Emma: soon, hopefully\n",
      "Will: you sure? Maybe you want me to pick you up?\n",
      "Emma: no no it's alright. I'll be home soon, i'll tell you when I get home. \n",
      "Will: Alright, love you. \n",
      "Emma: love you too. \n",
      "Model Summary    : Emma will be home soon. She will tell Will when she gets home.\n",
      "Reference Summary: Emma will be home soon and she will let Will know.\n",
      "\n",
      "Sample 5:\n",
      "Original Dialogue: Ollie: Hi , are you in Warsaw\n",
      "Jane: yes, just back! Btw are you free for diner the 19th?\n",
      "Ollie: nope!\n",
      "Jane: and the  18th?\n",
      "Ollie: nope, we have this party and you must be there, remember?\n",
      "Jane: oh right! i lost my calendar..  thanks for reminding me\n",
      "Ollie: we have lunch this week?\n",
      "Jane: with pleasure!\n",
      "Ollie: friday?\n",
      "Jane: ok\n",
      "Jane: what do you mean \" we don't have any more whisky!\" lol..\n",
      "Ollie: what!!!\n",
      "Jane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\n",
      "Ollie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\n",
      "Jane: dont' worry, we'll check on friday.\n",
      "Ollie: don't forget to bring some sun with you\n",
      "Jane: I can't wait to be in Morocco..\n",
      "Ollie: enjoy and see you friday\n",
      "Jane: sorry Ollie, i'm very busy, i won't have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\n",
      "Ollie: ok for tea!\n",
      "Jane: I'm on my way..\n",
      "Ollie: tea is ready, did you bring the pastries?\n",
      "Jane: I already ate them all... see you in a minute\n",
      "Ollie: ok\n",
      "Model Summary    : Jane is in Warsaw. She lost her calendar. She's on her way to Morocco.\n",
      "Reference Summary: Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
      "\n",
      "Sample 6:\n",
      "Original Dialogue: Benjamin: Hey guys, what are we doing with the keys today?\n",
      "Hilary: I've got them. Whoever wants them can meet me at lunchtime or after\n",
      "Elliot: I'm ok. We're meeting for the drinks in the evening anyway and I guess we'll be going back to the apartment together?\n",
      "Hilary: Yeah, I guess so\n",
      "Daniel: I'm with Hilary atm and won't let go of her for the rest of the day, so any option you guys choose is good for me\n",
      "Benjamin: Hmm I might actually pass by at lunchtime, take the keys and go take a nap. I'm sooo tired after yesterday\n",
      "Hilary: Sounds good. We'll be having lunch with some French people (the ones who work on the history of food in colonial Mexico - I already see you yawning your head off)\n",
      "Benjamin: YAAAAWN ðŸ™Š Where and where are you meeting?\n",
      "Hilary: So I'm meeting them at the entrance to the conference hall at 2 pm and then we'll head to this place called La Cantina. Italian cuisine, which is quite funny, but that's what they've chosen\n",
      "Benjamin: Interesting ðŸ˜± To be honest, Hilary, I almost feel like changing my mind. Wanting to take this nap might end up costing me to dear\n",
      "Hilary: Oh come on ðŸ˜‚\n",
      "Benjamin: All these terrible obstacles on mu way to bed might just prove to much to take\n",
      "Hilary: We'll try to avoid talking about their subject of research. Oh wait, no, I'm actually meeting them because I wanted to chat about their research lol\n",
      "Elliot: ðŸ™‰\n",
      "Hilary: Do join us, we're going to have fun. And then you'll take the keys and take this most deserved of naps\n",
      "Elliot: Sounds like a plan ðŸ˜‚\n",
      "Hilary: ðŸ˜Ž\n",
      "Elliot: See you at 2 then xx\n",
      "Model Summary    : Benjamin, Elliot, Hilary and Daniel are meeting at La Cantina at 2 pm. They're going to have lunch with French people who work on the history of food in colonial Mexico. Hilary is meeting them at the entrance to the conference hall at 2 pm and then they'll head to La\n",
      "Reference Summary: Hilary has the keys to the apartment. Benjamin wants to get them and go take a nap. Hilary is having lunch with some French people at La Cantina. Hilary is meeting them at the entrance to the conference hall at 2 pm. Benjamin and Elliot might join them. They're meeting for the drinks in the evening.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 113. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 7:\n",
      "Original Dialogue: Max: Know any good sites to buy clothes from?\n",
      "Payton: Sure :) <file_other> <file_other> <file_other> <file_other> <file_other> <file_other> <file_other>\n",
      "Max: That's a lot of them!\n",
      "Payton: Yeah, but they have different things so I usually buy things from 2 or 3 of them.\n",
      "Max: I'll check them out. Thanks. \n",
      "Payton: No problem :)\n",
      "Max: How about u?\n",
      "Payton: What about me?\n",
      "Max: Do u like shopping?\n",
      "Payton: Yes and no.\n",
      "Max: How come?\n",
      "Payton: I like browsing, trying on, looking in the mirror and seeing how I look, but not always buying.\n",
      "Max: Y not?\n",
      "Payton: Isn't it obvious? ;)\n",
      "Max: Sry ;)\n",
      "Payton: If I bought everything I liked, I'd have nothing left to live on ;)\n",
      "Max: Same here, but probably different category ;)\n",
      "Payton: Lol\n",
      "Max: So what do u usually buy?\n",
      "Payton: Well, I have 2 things I must struggle to resist!\n",
      "Max: Which are?\n",
      "Payton: Clothes, ofc ;)\n",
      "Max: Right. And the second one?\n",
      "Payton: Books. I absolutely love reading!\n",
      "Max: Gr8! What books do u read?\n",
      "Payton: Everything I can get my hands on :)\n",
      "Max: Srsly?\n",
      "Payton: Yup :)\n",
      "Model Summary    : Max will check out some good sites to buy clothes from. Payton will buy clothes and books.\n",
      "Reference Summary: Payton provides Max with websites selling clothes. Payton likes browsing and trying on the clothes but not necessarily buying them. Payton usually buys clothes and books as he loves reading.\n",
      "\n",
      "Sample 8:\n",
      "Original Dialogue: Rita: I'm so bloody tired. Falling asleep at work. :-(\n",
      "Tina: I know what you mean.\n",
      "Tina: I keep on nodding off at my keyboard hoping that the boss doesn't notice..\n",
      "Rita: The time just keeps on dragging on and on and on.... \n",
      "Rita: I keep on looking at the clock and there's still 4 hours of this drudgery to go.\n",
      "Tina: Times like these I really hate my work.\n",
      "Rita: I'm really not cut out for this level of boredom.\n",
      "Tina: Neither am I.\n",
      "Model Summary    : Rita is tired and falling asleep at work. Tina hates her work.\n",
      "Reference Summary: Rita and Tina are bored at work and have still 4 hours left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 111. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 9:\n",
      "Original Dialogue: Beatrice: I am in town, shopping. They have nice scarfs in the shop next to the church. Do you want one?\n",
      "Leo: No, thanks\n",
      "Beatrice: But you don't have a scarf.\n",
      "Leo: Because I don't need it.\n",
      "Beatrice: Last winter you had a cold all the time. A scarf could help.\n",
      "Leo: I don't like them.\n",
      "Beatrice: Actually, I don't care. You will get a scarf.\n",
      "Leo: How understanding of you!\n",
      "Beatrice: You were complaining the whole winter that you're going to die. I've had enough.\n",
      "Leo: Eh.\n",
      "Model Summary    : Leo doesn't need a scarf because he had a cold all the time last winter. Beatrice will buy him one.\n",
      "Reference Summary: Beatrice wants to buy Leo a scarf, but he doesn't like scarves. She cares about his health and will buy him a scarf no matter his opinion.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(samples):\n\u001b[0;32m     16\u001b[0m     dialogue \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 17\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialogue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Use max_new_tokens instead of max_length\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Dialogue:\u001b[39m\u001b[38;5;124m\"\u001b[39m, dialogue)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\text2text_generation.py:280\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m          ids of the summary.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\text2text_generation.py:173\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[0;32m    178\u001b[0m     ):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\base.py:1368\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1361\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1362\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         )\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\base.py:1375\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1374\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1375\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\base.py:1275\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1274\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1275\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\pipelines\\text2text_generation.py:202\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    200\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 202\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\generation\\utils.py:2254\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2246\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2247\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2248\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2249\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2250\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2251\u001b[0m     )\n\u001b[0;32m   2253\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2254\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2267\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2268\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2275\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\generation\\utils.py:3531\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3528\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m next_tokens \u001b[38;5;241m%\u001b[39m vocab_size\n\u001b[0;32m   3530\u001b[0m \u001b[38;5;66;03m# stateless\u001b[39;00m\n\u001b[1;32m-> 3531\u001b[0m beam_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3532\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_token_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3537\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_prompt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_prompt_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3542\u001b[0m beam_scores \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3543\u001b[0m beam_next_tokens \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\generation\\beam_search.py:269\u001b[0m, in \u001b[0;36mBeamSearchScorer.process\u001b[1;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# next tokens for this sentence\u001b[39;00m\n\u001b[0;32m    267\u001b[0m beam_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m beam_token_rank, (next_token, next_score, next_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m ):\n\u001b[0;32m    271\u001b[0m     batch_beam_idx \u001b[38;5;241m=\u001b[39m batch_idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_size \u001b[38;5;241m+\u001b[39m next_index\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# add to generated hypotheses if end of sentence\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_tensor.py:1012\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1003\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1004\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1009\u001b[0m         )\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1012\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1013\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;66;03m# save us work, and also helps keep trace ordering deterministic\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;66;03m# (e.g., if you zip(*hiddens), the eager map will force all the\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;66;03m# indexes of hiddens[0] before hiddens[1], while the generator\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;66;03m# map will interleave them.)\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "# Load the summarization pipeline for pegasus-samsum\n",
    "summarizer = pipeline(\"summarization\", model=\"transformersbook/pegasus-samsum\")\n",
    "\n",
    "# Load the JSON file (test.json)\n",
    "with open(\"test.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "# Take first 10 samples\n",
    "samples = data[:10]\n",
    "\n",
    "# Run summarization\n",
    "for i, sample in enumerate(samples):\n",
    "    dialogue = sample[\"dialogue\"]\n",
    "    summary = summarizer(\n",
    "        dialogue,\n",
    "        max_new_tokens=60,    # Use max_new_tokens instead of max_length\n",
    "        min_length=15,\n",
    "        do_sample=False,\n",
    "        truncation=True\n",
    "    )[0][\"summary_text\"]\n",
    "\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(\"Original Dialogue:\", dialogue)\n",
    "    print(\"Model Summary    :\", summary)\n",
    "    print(\"Reference Summary:\", sample[\"summary\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
